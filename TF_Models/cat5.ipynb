{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cat5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOnbhrwBi4kzXRFrBMNhAhv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wxjZNfBYBu-n","colab_type":"code","colab":{}},"source":["# QUESTION\n","#\n","# For this task you will need to train a neural network\n","# to predict sunspot activity using the Sunspots.csv dataset.\n","# Your neural network must  have an MAE\n","# of 0.12 or less on the normalized dataset for top marks.\n","# Code for normalizing the data is provided and should not be changed.\n","# At the bottom of this file, we provide  some testing\n","# code should you want to check your model.\n","\n","# Note: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure.\n","\n","\n","import csv\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","\n","# DO NOT CHANGE THIS CODE\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n","    urllib.request.urlretrieve(url, 'sunspots.csv')\n","\n","    time_step = []\n","    sunspots = []\n","\n","    with open('sunspots.csv') as csvfile:\n","      reader = csv.reader(csvfile, delimiter=',')\n","      next(reader)\n","      for row in reader:\n","          sunspots.append(float(row[2]))\n","          time_step.append(float(row[2]))\n","\n","    series = np.array(sunspots)\n","\n","    # DO NOT CHANGE THIS CODE\n","    # This is the normalization function\n","    min = np.min(series)\n","    max = np.max(series)\n","    series -= min\n","    series /= max\n","    time = np.array(time_step)\n","\n","    # The data should be split into training and validation sets at time step 3000\n","    # DO NOT CHANGE THIS CODE\n","    split_time = 3000\n","\n","\n","    time_train = time[:split_time]\n","    x_train = series[:split_time]\n","    time_valid = time[split_time:]\n","    x_valid = series[split_time:]\n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size = 30\n","    batch_size = 32\n","    shuffle_buffer_size = 1000\n","\n","\n","    train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n","\n","\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv1D(64, 5, strides=1, padding=\"same\", activation=\"relu\", input_shape=[None, 1]),\n","        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n","        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n","        tf.keras.layers.Dense(32, activation=\"relu\"),\n","        tf.keras.layers.Dense(16, activation=\"relu\"),\n","      # YOUR CODE HERE. Whatever your first layer is, the input shape will be [None,1] when using the Windowed_dataset above, depending on the layer type chosen\n","        tf.keras.layers.Dense(1)\n","    ])\n","    # PLEASE NOTE IF YOU SEE THIS TEXT WHILE TRAINING -- IT IS SAFE TO IGNORE\n","    # BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n","    # \t [[{{node IteratorGetNext}}]]\n","    #\n","\n","\n","    # YOUR CODE HERE TO COMPILE AND TRAIN THE MODEL\n","    class MyCallback(tf.keras.callbacks.Callback):\n","        def on_epoch_end(self, epoch, logs={}):\n","            if (logs.get(\"mae\")<0.12):\n","                self.model.stop_training=True\n","    callback = MyCallback()\n","    model.compile(loss=tf.keras.losses.Huber(), optimizer='adam', metrics=[\"mae\"])\n","    model.fit(train_set, epochs=20,callbacks=[callback])\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, this .h5 model will be\n","# sent to the testing infrastructure for scoring.\n","\n","# You must use the Submit and Test button to submit your model\n","# at least once in each category before you finally submit your exam.\n","\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")\n","\n","\n","\n","# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n","# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n","#def model_forecast(model, series, window_size):\n","#    ds = tf.data.Dataset.from_tensor_slices(series)\n","#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n","#    ds = ds.flat_map(lambda w: w.batch(window_size))\n","#    ds = ds.batch(32).prefetch(1)\n","#    forecast = model.predict(ds)\n","#    return forecast\n","\n","\n","#window_size = # YOUR CODE HERE\n","#rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n","#rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]\n","\n","#result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n","\n","## To get the maximum score, your model must have an MAE OF .12 or less.\n","## When you Submit and Test your model, the grading infrastructure\n","## converts the MAE of your model to a score from 0 to 5 as follows:\n","\n","#test_val = 100 * result\n","#score = math.ceil(17 - test_val)\n","#if score > 5:\n","#    score = 5\n","\n","#print(score)"],"execution_count":0,"outputs":[]}]}